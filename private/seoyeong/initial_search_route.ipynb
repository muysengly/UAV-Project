{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "pNDoDvq_947U"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the grid world dimensions and number of gus\n",
        "GRID_SIZE = 100\n",
        "NUM_USERS = 13\n",
        "\n",
        "# Q-learning parameters\n",
        "MAX_STEPS = 1\n",
        "LEARNING_RATE = 0.1\n",
        "DISCOUNT_FACTOR = 0.99\n",
        "\n",
        "# Exploration parameters\n",
        "EPSILON_VALUES = [0.8, 0.6, 0.4, 0.3, 0.2, 0.15, 0.1, 0.05, 0.03, 0.01]"
      ],
      "metadata": {
        "id": "0u35p4xn96qy"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize grid world environments\n",
        "def initialize_env():\n",
        "    env = np.random.randint(0, GRID_SIZE, size=(NUM_USERS, 2))\n",
        "    print(\"Initial Gus Positions:\")\n",
        "    print(env)\n",
        "    return env"
      ],
      "metadata": {
        "id": "Zq6SAkLC98Pw"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial search route for reference\n",
        "INITIAL_SEARCH_ROUTE = [\n",
        "    [15,5],\n",
        "    [15,25],\n",
        "    [15,45],\n",
        "    [15,65],\n",
        "    [15,85],\n",
        "    [35,85],\n",
        "    [55,85],\n",
        "    [75,85],\n",
        "    [95,85],\n",
        "    [95,65],\n",
        "    [95,45],\n",
        "    [95,25],\n",
        "    [95,5],\n",
        "    [75,5],\n",
        "    [55,5],\n",
        "    [35,5],\n",
        "    [35,25],\n",
        "    [35,45],\n",
        "    [35,65],\n",
        "    [55,65],\n",
        "    [75,65],\n",
        "    [75,45],\n",
        "    [75,25],\n",
        "    [55,25],\n",
        "    [55,45]\n",
        "]"
      ],
      "metadata": {
        "id": "rrk4hrYe_ioR"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if a gu is found within the search radius\n",
        "def is_gu_within_radius(gu_positions, state):\n",
        "    num_gus_within_radius = 0\n",
        "    for gu in gu_positions:\n",
        "        distance = np.sqrt((state[0] - gu[0]) ** 2 + (state[1] - gu[1]) ** 2)\n",
        "        if distance <= 17:  # Check if the distance is less than or equal to 17\n",
        "            num_gus_within_radius += 1\n",
        "    return num_gus_within_radius"
      ],
      "metadata": {
        "id": "9PsqP1Bfvy4s"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if a gu is found within the search radius\n",
        "def is_gu_found(state, env):\n",
        "    gus_found = 0\n",
        "    for gu in env:\n",
        "        if is_gu_within_radius(gu, state):\n",
        "            gus_found += 1\n",
        "    return gus_found"
      ],
      "metadata": {
        "id": "4PsWYtjGKtQ8"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate reward based on the next state and environment\n",
        "def get_reward(state, env):\n",
        "    reward = -1  # Default reward for movement\n",
        "    gus_in_radius = is_gu_within_radius(env, state)\n",
        "    env = [gu for gu in env if not is_gu_within_radius([gu], state)]  # Remove gus within radius\n",
        "\n",
        "    if gus_in_radius > 0:\n",
        "        reward += 10 * gus_in_radius  # Plus reward for finding gus within the radius\n",
        "\n",
        "    return reward, env, gus_in_radius"
      ],
      "metadata": {
        "id": "O2_HT-0fk84K"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if all gus are collected\n",
        "def all_gus_collected(env):\n",
        "    return len(env) == 0"
      ],
      "metadata": {
        "id": "pocmS0u3-EEp"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the next state based on current state and action\n",
        "def get_next_state(state, action):\n",
        "    if action == 0:  # Move up\n",
        "        return max(state[0] - 1, 0), state[1]\n",
        "    elif action == 1:  # Move down\n",
        "        return min(state[0] + 1, GRID_SIZE - 1), state[1]\n",
        "    elif action == 2:  # Move left\n",
        "        return state[0], max(state[1] - 1, 0)\n",
        "    else:  # Move right\n",
        "        return state[0], min(state[1] + 1, GRID_SIZE - 1)"
      ],
      "metadata": {
        "id": "OGE1Q6Lz-Cmw"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate sequential search positions covering the entire grid\n",
        "def generate_search_positions():\n",
        "    positions = []\n",
        "    for i in range(GRID_SIZE):\n",
        "        for j in range(GRID_SIZE):\n",
        "            positions.append([i, j])\n",
        "    return positions"
      ],
      "metadata": {
        "id": "Gq7fu4h6RQCl"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q-learning using NumPy with searcher's movement and search radius\n",
        "def q_learning(env, epsilon, reference_route):\n",
        "    q_table = np.zeros((GRID_SIZE, GRID_SIZE, 4))  # Three dimensions: x, y, and actions\n",
        "    rewards = []\n",
        "\n",
        "    search_route = reference_route.copy()  # Copy the initial search route\n",
        "    current_index = 0  # Index to keep track of the current position in search_route\n",
        "    visited_points = set()  # Set to store visited points\n",
        "\n",
        "    total_gus_found = 0  # Counter for total gus found across all episodes\n",
        "    total_reward = 0\n",
        "    gus_found = 0  # Counter for gus found in this episode\n",
        "\n",
        "    for step in range(MAX_STEPS):\n",
        "        state = tuple(search_route[0])  # Convert to tuple\n",
        "\n",
        "        if state not in visited_points:\n",
        "            visited_points.add(state)\n",
        "\n",
        "            for _ in range(20):  # Move 20 units at each step\n",
        "                state_int = (int(state[0]), int(state[1]))  # Convert to integer tuple for accessing q_table\n",
        "                action = np.argmax(q_table[state_int[0], state_int[1], :])  # Exploit learned values\n",
        "                next_state = get_next_state(list(state_int), action)  # Convert to list for updating\n",
        "\n",
        "                next_state_int = (int(next_state[0]), int(next_state[1]))  # Convert to integer tuple\n",
        "\n",
        "                reward, env, gus_in_radius = get_reward(next_state, env)  # Update env after gu found\n",
        "\n",
        "                # Update q_table using indexing\n",
        "                q_table[state_int[0], state_int[1], action] += LEARNING_RATE * (\n",
        "                    reward + DISCOUNT_FACTOR ** (_ + 1) * np.max(q_table[next_state_int[0], next_state_int[1], :])\n",
        "                    - q_table[state_int[0], state_int[1], action])\n",
        "\n",
        "                total_reward += reward\n",
        "                total_gus_found += gus_in_radius  # Accumulate gus found within radius\n",
        "\n",
        "                if all_gus_collected(env):\n",
        "                    break\n",
        "\n",
        "                state = tuple(next_state_int)  # Convert back to tuple for dictionary key\n",
        "\n",
        "                if gus_in_radius > 0:\n",
        "                    env = [gu for gu in env if not is_gu_within_radius([gu], next_state)]  # Remove gus within radius\n",
        "\n",
        "            # Rotate the search route\n",
        "            search_route.append(search_route.pop(0))\n",
        "\n",
        "            if all_gus_collected(env):\n",
        "                break\n",
        "\n",
        "        rewards.append(total_reward)\n",
        "        total_gus_found += gus_found  # Accumulate gus found across episodes\n",
        "\n",
        "    return q_table, rewards, total_gus_found"
      ],
      "metadata": {
        "id": "uLqPRg8m-BEb"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the learned route\n",
        "def visualize_route(q_table, env):\n",
        "    route = []\n",
        "    state = env[0]\n",
        "\n",
        "    while not all_gus_collected(env):\n",
        "        action = np.argmax(q_table[state[0], state[1], :])\n",
        "        next_state = get_next_state(state, action)\n",
        "        route.append(next_state)\n",
        "        state = next_state\n",
        "        if tuple(state) in env.tolist():\n",
        "            env = np.delete(env, np.where((env == state).all(axis=1))[0][0], axis=0)\n",
        "\n",
        "    route = np.array(route)\n",
        "    sns.set_style(\"whitegrid\")\n",
        "    plt.figure(figsize=(10, 10))\n",
        "\n",
        "    # Plot search route and gus positions\n",
        "    sns.scatterplot(x=route[:, 1], y=route[:, 0], color='blue', s=50, label='Search Route')\n",
        "    sns.scatterplot(x=env[:, 1], y=env[:, 0], color='red', marker='x', s=100, label='Gus Positions')\n",
        "\n",
        "    # Plot search range circles around gus positions\n",
        "    for gu in env:\n",
        "        circle = plt.Circle((gu[1], gu[0]), radius=17, color='green', fill=False, linestyle='dashed')\n",
        "        plt.gca().add_patch(circle)\n",
        "\n",
        "    plt.title(\"Search Route Visualization\")\n",
        "    plt.xlabel(\"X Position\")\n",
        "    plt.ylabel(\"Y Position\")\n",
        "    plt.xlim(0, GRID_SIZE)\n",
        "    plt.ylim(0, GRID_SIZE)\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "A6ZYP3-HS0XL"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epsilon in EPSILON_VALUES:\n",
        "    env = initialize_env()\n",
        "    q_table, rewards, gus_found = q_learning(env, epsilon, INITIAL_SEARCH_ROUTE)\n",
        "\n",
        "    total_reward = sum(rewards)\n",
        "    print(f\"Epsilon: {epsilon}, gus Found: {gus_found}, Total Reward: {total_reward}\")\n",
        "\n",
        "    #visualize_route(q_table, env)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hR1QHuNp-HJJ",
        "outputId": "8ac49e76-29f2-41de-f97d-e04b7a8c6d97"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Gus Positions:\n",
            "[[38 91]\n",
            " [25 95]\n",
            " [65 32]\n",
            " [68 80]\n",
            " [95 74]\n",
            " [46  4]\n",
            " [92 27]\n",
            " [89 61]\n",
            " [24  8]\n",
            " [16 15]\n",
            " [33 69]\n",
            " [ 2 63]\n",
            " [86 76]]\n",
            "Epsilon: 0.8, gus Found: 2, Total Reward: 0\n",
            "Initial Gus Positions:\n",
            "[[62 82]\n",
            " [36 42]\n",
            " [75 69]\n",
            " [83 92]\n",
            " [66 16]\n",
            " [23 63]\n",
            " [ 0 64]\n",
            " [84 95]\n",
            " [60 11]\n",
            " [67 41]\n",
            " [86  1]\n",
            " [65 76]\n",
            " [21 66]]\n",
            "Epsilon: 0.6, gus Found: 0, Total Reward: -20\n",
            "Initial Gus Positions:\n",
            "[[ 8 98]\n",
            " [36 29]\n",
            " [67 14]\n",
            " [41 55]\n",
            " [23 47]\n",
            " [43 70]\n",
            " [ 7 20]\n",
            " [73 99]\n",
            " [67 46]\n",
            " [10 37]\n",
            " [ 8 80]\n",
            " [23 62]\n",
            " [96 73]]\n",
            "Epsilon: 0.4, gus Found: 1, Total Reward: -10\n",
            "Initial Gus Positions:\n",
            "[[99 26]\n",
            " [29  2]\n",
            " [62  0]\n",
            " [55  9]\n",
            " [31 62]\n",
            " [83 81]\n",
            " [30 50]\n",
            " [ 8 86]\n",
            " [28 42]\n",
            " [21 50]\n",
            " [22 97]\n",
            " [30  0]\n",
            " [79 28]]\n",
            "Epsilon: 0.3, gus Found: 2, Total Reward: 0\n",
            "Initial Gus Positions:\n",
            "[[30 61]\n",
            " [19 37]\n",
            " [30  2]\n",
            " [31 43]\n",
            " [ 6 83]\n",
            " [84 32]\n",
            " [65 43]\n",
            " [75 16]\n",
            " [88 28]\n",
            " [67 93]\n",
            " [45 93]\n",
            " [84 47]\n",
            " [29 15]]\n",
            "Epsilon: 0.2, gus Found: 1, Total Reward: -10\n",
            "Initial Gus Positions:\n",
            "[[29 81]\n",
            " [60 50]\n",
            " [62 78]\n",
            " [94 42]\n",
            " [84 89]\n",
            " [83 97]\n",
            " [31 99]\n",
            " [70 26]\n",
            " [86 23]\n",
            " [ 8 63]\n",
            " [ 6 31]\n",
            " [40 75]\n",
            " [24 29]]\n",
            "Epsilon: 0.15, gus Found: 0, Total Reward: -20\n",
            "Initial Gus Positions:\n",
            "[[20 79]\n",
            " [54 53]\n",
            " [64 33]\n",
            " [61 91]\n",
            " [36 23]\n",
            " [71 73]\n",
            " [ 9 18]\n",
            " [32 86]\n",
            " [58 83]\n",
            " [91 20]\n",
            " [48 62]\n",
            " [18 14]\n",
            " [ 6 46]]\n",
            "Epsilon: 0.1, gus Found: 2, Total Reward: 0\n",
            "Initial Gus Positions:\n",
            "[[47 86]\n",
            " [ 3 90]\n",
            " [53 33]\n",
            " [ 8 90]\n",
            " [30 70]\n",
            " [36 52]\n",
            " [58 55]\n",
            " [ 2  1]\n",
            " [91 98]\n",
            " [24  7]\n",
            " [94 11]\n",
            " [94 43]\n",
            " [83 96]]\n",
            "Epsilon: 0.05, gus Found: 2, Total Reward: 0\n",
            "Initial Gus Positions:\n",
            "[[39 60]\n",
            " [85 18]\n",
            " [12 11]\n",
            " [19 91]\n",
            " [68 88]\n",
            " [31 27]\n",
            " [12 92]\n",
            " [80 28]\n",
            " [ 2 96]\n",
            " [72 71]\n",
            " [95 45]\n",
            " [16  0]\n",
            " [49 11]]\n",
            "Epsilon: 0.03, gus Found: 2, Total Reward: 0\n",
            "Initial Gus Positions:\n",
            "[[ 9 33]\n",
            " [16  7]\n",
            " [50 50]\n",
            " [33 81]\n",
            " [11 33]\n",
            " [99 28]\n",
            " [73 54]\n",
            " [22 30]\n",
            " [27 27]\n",
            " [81 24]\n",
            " [74 97]\n",
            " [65 36]\n",
            " [52 46]]\n",
            "Epsilon: 0.01, gus Found: 1, Total Reward: -10\n"
          ]
        }
      ]
    }
  ]
}